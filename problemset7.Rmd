---
title: "INFX 573 Problem Set 7 - Prediction"
author: "Chang(Jay)Liu"
date: "Due: Tueday, November 29, 2015"
output: pdf_document
header-includes:
- \newcommand{\benum}{\begin{enumerate}}
- \newcommand{\eenum}{\end{enumerate}}
- \newcommand{\bitem}{\begin{itemize}}
- \newcommand{\eitem}{\end{itemize}}
---
##### Collaborators: 

##### Instructions: #####

Before beginning this assignment, please ensure you have access to R and RStudio. 

1. Download the `problemset7.Rmd` file from Canvas. Open `problemset7.Rmd` in RStudio and supply your solutions to the assignment by editing `problemset7.Rmd`. 

2. Replace the "Insert Your Name Here" text in the `author:` field with your own full name. Any collaborators must be listed on the top of your assignment. 

3. Be sure to include well-documented (e.g. commented) code chucks, figures and clearly written text chunk explanations as necessary. Any figures should be clearly labeled and appropriately referenced within the text. 

4. Collaboration on problem sets is acceptable, and even encouraged, but each student must turn in an individual write-up in his or her own words and his or her own work. The names of all collaborators must be listed on each assignment. Do not copy-and-paste from other students' responses or code.

5. When you have completed the assignment and have **checked** that your code both runs in the Console and knits correctly when you click `Knit PDF`, rename the R Markdown file to `YourLastName_YourFirstName_ps7.Rmd`, knit a PDF and submit the PDF file on Canvas.

##### Setup: #####

In this problem set you will need, at minimum, the following R packages.

```{r Setup, message=FALSE}
# Load standard libraries
library(tidyverse)
library(gridExtra)
library(MASS)
library(pROC)
library(arm)
library(randomForest)
library(xgboost)
library(Amelia)
library(ROCR)
```

\noindent \textbf{Data:} In this problem set we will use the \texttt{titanic} dataset used previously in class. The Titanic text file contains data about the survival of passengers aboard the Titanic. Table \ref{tab:data} contains a description of this data. 
\vspace{.1in}

```{r Load data}
# Load data
titanic_data <- read.csv('titanic.csv')
#str(data) # explore data structure
str(titanic_data)

#check for missing data in the dataset
missmap(titanic_data, main = "Missing values vs observed")
#count the number of NAs in age
summary(titanic_data$age)
#fill up values for null values. 
for(i in 1:ncol(titanic_data)){
  titanic_data[is.na(titanic_data[,i]), i] <- mean(titanic_data[,i], na.rm = TRUE)
}
#check for remaining NAs
which(is.na(titanic_data$age))
#convert name column type to string from factor
titanic_data$name <- as.character(titanic_data$name)

#separate title from the name column
titanic_data$title <-sapply(titanic_data$name, FUN=function(x) {strsplit(x, split='[,.]')[[1]][2]})
#remove the space before the title value
titanic_data$title <- sub(' ','',titanic_data$title)

#combine Mme and Mile into Mile
titanic_data$title[titanic_data$title %in% c('Mme', 'Mlle')] <- 'Mlle'
#combine Capt,Don,Major,and Sir into Sir
titanic_data$title[titanic_data$title %in% c('Capt', 'Don', 'Major', 'Sir')] <- 'Sir'
#combine Dona, Lady, the Countess, Jonkheer into Lady
titanic_data$title[titanic_data$title %in% c('Dona', 'Lady', 'the Countess', 'Jonkheer')] <- 'Lady' 
```

\begin{table}[ht]
\centering
\begin{tabular}{|l|l|}
\hline
{\bf Variable} & {\bf Description} \\ \hline \hline
pclass      &    Passenger Class \\
            &    (1 = 1st; 2 = 2nd; 3 = 3rd) \\ \hline
survived    &    Survival \\
            &    (0 = No; 1 = Yes) \\ \hline
name        &    Name \\ \hline
sex         &    Sex \\ \hline
age         &    Age \\ \hline
sibsp       &    Number of Siblings/Spouses Aboard \\ \hline
parch       &    Number of Parents/Children Aboard \\ \hline 
ticket      &    Ticket Number \\ \hline
fare        &    Passenger Fare \\ \hline
cabin       &    Cabin \\ \hline
embarked    &    Port of Embarkation \\
            &    (C = Cherbourg; Q = Queenstown; S = Southampton) \\ \hline
boat        &    Lifeboat \\ \hline
body        &    Body Identification Number \\ \hline
home.dest   &    Home/Destination \\
\hline
\end{tabular}
\caption{Description of variables in the Titanic Dataset}
\label{tab:data}
\end{table}
\vspace{.1in}

\newpage

\benum
\item As part of this assignment we will evaluate the performance of a few different statistical learning methods.  We will fit a particular statistical learning method on a set of \emph{training} observations and measure its performance on a set of \emph{test} observations. 

\bitem
\item[(a)] Discuss the advantages of using a training/test split when evaluating statistical models.

We build predictive models to perform on future data,since we don't have future dataset hand, the split of current data into training and test partitions, this will give us a more realistic evalution of the performance in our model. We are using the data split based on two assumptions:
1. The real world processes we wish to model are expected to remain relatively stable over time so that a well-constructed model built on current data is reasonably expected to perform adequately on new data (e.g., monthly data) 
2.the data available for analytics fairly represents the real world processes we wish to model

\item[(b)] Split your data into a \emph{training} and \emph{test} set based on an 80-20 split, in other words, 80\% of the observations will be in the training set.
\eitem
```{r 80-20 data split}

#re-cast categorical variables to be factor data type
titanic_data$pclass <- as.factor(titanic_data$pclass)
titanic_data$survived <- as.factor(titanic_data$survived)

#set seed to get the same seuquence next time
set.seed(1234)

#Take a random sample with size of the number of rows and 
#assign 1 or 2 to each rows with a probability of 0.8 or 0.2
ind <- sample(2, nrow(titanic_data), replace = TRUE, prob=c(0.8,0.2))

#Create training dataset
titanic_training <- titanic_data[ind==1,1:15]
#Create testing dataset
titanic_testing <- titanic_data[ind==2,1:15]
```


\item In this problem set our goal is to predict the survival of passengers. First consider training a logistic regression model for survival that controls for the socioeconomic status of the passenger. 

\bitem
\item[(a)] Fit the model described above using the \texttt{glm} function in R. 
```{r}
#convert pclass to a factor
titanic_data$pclass<- as.factor(titanic_data$pclass)

#fit a logistic regression model based on socioeconomic status
glm.fit = glm(survived~ pclass , data = titanic_training, family = binomial)
#exam the output of the logistic regression model
summary(glm.fit)

#exam the coefficients of among predictors in the logistics regression model. 
summary(glm.fit)$coef
```


Note: I suggested \texttt{bayesglm} as well in case the model was unstable (you can see this with extremely large s.e. estimates for the coefficients). Be sure you included \texttt{pclass} as a \texttt{factor} because it is a categorical variable!
\item[(b)] What might you conclude based on this model about the probability of survival for lower class passengers?
\eitem
```{r}

```


\item Next, let's consider the performance of this model. 

\bitem
\item[(a)] Predict the survival of passengers for each observation in your test set using the model fit in Problem 2. Save these predictions as \texttt{yhat}.
```{r}
#predict thesurvival of passengers for each obervation in the test dataset
yhat <-predict(glm.fit, titanic_testing,type="response" )
#exam first 10 predicted probabily that the passenger will survive 
yhat[1:10]
#see if 1 represetns survived or not
contrasts(titanic_data$survived)
```

\item[(b)] Use a threshold of 0.5 to classify predictions. What is the number of false positives on the test data? Interpret this in your own words.
```{r confusion matrix}
#count the number of observations in testing dataset
nrow(titanic_testing)

glm.pred = rep("not survived",265)
glm.pred[yhat> 0.5] = "Survived"

#create a confusion matrix to determine how many observaions were false positives
table(glm.pred,titanic_testing$survived)
#calcuate the fraction ofdays for which the prediction was correct
(136 + 33)/265
```
The number of false positive is 71, which means out of all 265 observations, 71 of them were predicted to survive, but they did not end out surviving. The probability of the model correctly predcting the survival of passenger is 0.63, which is 63% of the time. 

\item[(c)] Using the \texttt{roc} function, plot the ROC curve for this model. Discuss what you find.
\eitem
```{r ROC curve}

#create the ROC curve for the logisitc regression model
ROC1<- roc(titanic_testing$survived, yhat)
#plot the ROC curve
plot(ROC1,col="red")

#Calculate the area under the curve
AUC <- auc(ROC1)
AUC
```
The model is reasonably accurate based on the AUC plot. 

\item Suppose we use the data to construct a new predictor variable based on a passenger's listed title (i.e. Mr., Mrs., Miss., Master). 

\bitem
\item[(a)] Why might this be an interesting variable to help predict passenger survival?

Passengers' listed title might be interesting to predict passenger for a number of reasons. First, passengers with certain titles might have recevived more help durng the rescuing process. For example, capttain, Don, Major, and Sir, all of which are either military titles, or wealthy people. Second, passengers with "Mrs" title may have children with them, which could have either reduce or increase their change of survivial.  Third, female passengers with titles such as Dona, Lady, Jonkheer, and Countess are also of noble birth. Last, commoners who have just Mr. and Ms probably came in second interms being rescued.    


\item[(b)] Write a function to add this predictor to your dataset.
I have already added the 'title' predictor during during the data load chunk. The new predictor was added to the dataset before the 80-20 split to avoid redundancy to added it twice to both testing and training dataset. 
```{r}
#separate title from the name column
#titanic_data$title <-sapply(titanic_data$name, FUN=function(x) {strsplit(x, split='[,.]')[[1]][2]})
#remove the space before the title value
#titanic_data$title <- sub(' ','',titanic_data$title)

```

\item[(c)] Fit a second logistic regression model including this new feature. Use the \texttt{summary} function to look at the model. Did this new feature improve the model? 
```{r}
#fit a second logistic regression model with title feature
glm.fit2 = glm(survived ~ pclass + title, data = titanic_training, family = binomial)
#exam the output of the logstic model
summary(glm.fit2)
summary(glm.fit)
```
This model is sligtly better fited than the previous model that has only pclass as the predictor. 

\item[(d)] Comment on the overall fit of this model. For example, you might consider exploring when misclassification occurs.

There are titless within the title column that are not statistically significant to predict the chance of survival, this may have impacted the accuracy and precision of the model. 

\item[(e)] Predict the survival of passengers for each observation in your test data using the new model. Save these predictions as \texttt{yhat2}.
```{r}
#predict the survival of passengers with the addition of title predictor
yhat2 <- predict(glm.fit2, data = titanic_testing, type ="response")
#list the first 10 probabilities
yhat2[1:10]
```


\eitem

\item Another very popular classifier used in data science is called a \emph{random  forest}\footnote{\url{https://www.stat.berkeley.edu/\~breiman/RandomForests/cc_home.htm}}.

\bitem
\item[(a)] Use the \texttt{randomForest} function to fit a random forest model with passenger class and title as predictors. Make predictions for the test set using the random forest model. Save these predictions as \texttt{yhat3}.
```{r}
set.seed(1)
#recast title column from character to factor for the model
titanic_training$title = as.factor(titanic_training$title)
#fit the random forest model
forest.fit <- randomForest(survived ~ pclass + title, data = titanic_training,importance=TRUE,ntree =2000)
#exam the output
summary(forest.fit)
#look at what variables are important
varImpPlot(forest.fit)

#recast title column from character to factor for the model
titanic_testing$title = as.factor(titanic_testing$title)

#set variables to the same level for each predictor in training and testing dataset
levels(titanic_testing$title) <-levels(titanic_training$title)
#predict with random forest mode
yhat3<-predict(forest.fit,newdata = titanic_testing)
#exam the results.
summary(yhat3)

(prediction_test_acc1 <- sum(yhat3 == titanic_testing$survived)/nrow(titanic_testing))

```
Based on the plot, it seems title variable has high mean decrease accuracy and mean decrease Gini value, since he accuracy one tests to see how worse the model performs without each variable, so a high decrease in accuracy would be expected for very predictive variables. These two tests tell us title predicator is very important in predicting the survival of passengers.

\item[(b)] Develop your own random forest model, attempting to improve the model performance.  Make predictions for the test set using your new random forest model. Save these predictions as \texttt{yhat4}.
```{r}
#new random forest model with two more variables sex and 
forest.fin <- randomForest(survived ~ pclass + title + sex + age, data = titanic_training, importance= TRUE,ntree = 2000 )
#plot the model to see which variable is more important
varImpPlot(forest.fin)
#make a new prediction2
yhat4 <- predict(forest.fin,newdata = titanic_testing, importance="none")
#exam the ouput of the prediction
summary(yhat4)


#prediction accuracy
(prediction_test_acc2 <- sum(yhat4 == titanic_testing$survived)/nrow(titanic_testing))
```
The model is slightly improved in its accuracy by adding a few more predictors. 

\item[(c)] Compare the accuracy of each of the models from this problem set using ROC curves. Comment on which statistical learning method works best for predicting survival of the Titanic passengers. 
```{r}
#convert the pclass variable to numeric
titanic_testing$pclass<- as.factor(titanic_testing$pclass)
titanic_testing$title<- as.factor(titanic_testing$title)


#ROC2<-roc(titanic_testing$survived[], forest.fin )
#Error in roc.default(titanic_testing$survived[], forest.fin) : Predictor must be numeric or ordered.
```

\item Finally, we will explore a gradient boosted tree model, using the `xgboost` package written by your fellow UW student Tianqi Chen. `xgboost` stands for ``Extreme Gradient Boosting'', which is state-of-the-art software known for its fast training time and predictive accuracy.

\bitem
\item[(a)] The XGB algorithm can only handle numeric data, so first we need to convert all categorical variables to a different representation, such as a sparse matrix.

```{r}
library(Matrix)
sparse.matrix.train <- sparse.model.matrix(survived~pclass + sex + title -1, data = titanic_training) #converts train set factors to columns
sparse.matrix.test <-  sparse.model.matrix(survived~pclass + sex + title -1, data = titanic_testing) #converts test set factors to columns
output_vector = titanic_training$survived #output vector to be predicted
```

\item[(b)] The following code fits a boosted tree model and produces a plot. Run the code and provide an explanation of the resulting plot.

```{r}
#could not run the code. 
#Error in xgb.iter.update(fd$booster, fd$dtrain, i - 1, obj) : label must be in [0,1] for logistic regression


#xgb.model.one <- xgb.cv(data= sparse.matrix.train,     #train sparse matrix
                    #   label= output_vector,    #output vector to be predicted 
                  #     eval.metric = 'logloss',     #model minimizes Root Mean Squared Error
                #       objective = "reg:logistic", #regression
                 #      nfold = 10,
               #        #tuning parameters
                 #      max.depth = 3,            #Vary btwn 3-15
                #       eta = 0.05,                #Vary btwn 0.1-0.3
                #       nthread = 5,             #Increase this to improve speed
               #        subsample= 1,            #Vary btwn 0.8-1
              #         colsample_bytree = 0.5,   #Vary btwn 0.3-0.8
               #        lambda = 0.5,             #Vary between 0-3
                #       alpha = 0.5,              #Vary between 0-3
                 #      min_child_weight = 3,     #Vary btwn 1-10
                  #     nround = 100             #Vary btwn 100-3000 based on max.depth, eta,subsample & colsample
                   #    )
#plot(data.frame(xgb.model.one)[,1], type='l', col='black', ylab= 'CV logloss Error', xlab='# of trees')
#lines(data.frame(xgb.model.one)[,3], type='l', lty=2, col='black')
```

\item[(c)] Modify the code to fit a boosted tree model that allows for 8 levels in each tree and uses a learning rate $\eta=.1$. Produce a visualization comparing the two models and explain what you can conclude about the new model. Which model do you prefer and why?
```{r}

```

\eitem


\eitem
\eenum
